{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> table {float:left} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style> table {float:left} </style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\monis\\anaconda3\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\monis\\anaconda3\\lib\\site-packages (4.31.1)\n",
      "Requirement already satisfied: lazyme in c:\\users\\monis\\anaconda3\\lib\\site-packages (0.0.22)\n",
      "Requirement already satisfied: nltk in c:\\users\\monis\\anaconda3\\lib\\site-packages (3.4)\n",
      "Requirement already satisfied: gensim in c:\\users\\monis\\anaconda3\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: six in c:\\users\\monis\\anaconda3\\lib\\site-packages (from nltk) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in c:\\users\\monis\\anaconda3\\lib\\site-packages (from nltk) (3.4.0.3)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in c:\\users\\monis\\anaconda3\\lib\\site-packages (from gensim) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\monis\\anaconda3\\lib\\site-packages (from gensim) (1.14.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\monis\\anaconda3\\lib\\site-packages (from gensim) (1.0.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\monis\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim) (1.9.7)\n",
      "Requirement already satisfied: requests in c:\\users\\monis\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim) (2.18.4)\n",
      "Requirement already satisfied: boto>=2.32 in c:\\users\\monis\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim) (2.48.0)\n",
      "Requirement already satisfied: bz2file in c:\\users\\monis\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim) (0.98)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\monis\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (0.9.3)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in c:\\users\\monis\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (0.1.13)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.7 in c:\\users\\monis\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (1.12.120)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\monis\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\monis\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\monis\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\monis\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (2018.11.29)\n",
      "Requirement already satisfied: docutils>=0.10 in c:\\users\\monis\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.7->boto3->smart-open>=1.7.0->gensim) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in c:\\users\\monis\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.7->boto3->smart-open>=1.7.0->gensim) (2.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monis\\Anaconda3\\lib\\runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\monis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch tqdm lazyme nltk gensim\n",
    "#!python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm #tqdm for progress bar\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, tensor, autograd\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # Use the default NLTK tokenizer.\n",
    "    from nltk import word_tokenize, sent_tokenize \n",
    "    # Testing whether it works. \n",
    "    # Sometimes it doesn't work on some machines because of setup issues.\n",
    "    word_tokenize(sent_tokenize(\"This is a foobar sentence. Yes it is.\")[0])\n",
    "except: # Use a naive sentence tokenizer and toktok.\n",
    "    import re\n",
    "    from nltk.tokenize import ToktokTokenizer\n",
    "    # See https://stackoverflow.com/a/25736515/610569\n",
    "    sent_tokenize = lambda x: re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', x)\n",
    "    # Use the toktok tokenizer that requires no dependencies.\n",
    "    toktok = ToktokTokenizer()\n",
    "    word_tokenize = word_tokenize = toktok.tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification \n",
    "\n",
    "Text Categorization (textcat) is a common task in NLP. As long as, we have labelled data and we want to assign a discrete label to every input data point, it's a classification problem. E.g. \n",
    "\n",
    "| Tasks | Possible Labels | \n",
    "|:-|:-|\n",
    "| Sentiment analysis | Positive, Negative, Neutral | \n",
    "| Tweetstorm detection | True, False |\n",
    "| Author profiling | Author1, Author2, ... | \n",
    "| Language Identification | EN, ZH, DE, JA, FR, ...|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various datasets for sentiment classification, previously we looked at the movie reviews dataset in `nltk`. There's also this other popular IMDB movie reviews dataset from Stanford. Lets use that.\n",
    "\n",
    "Download the dataset from http://ai.stanford.edu/~amaas/data/sentiment/ and put it in the same directory as where you're running this jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Munge the data!\n",
    "\n",
    "As always we have to preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12500it [00:40, 305.35it/s]\n",
      "12500it [00:55, 225.68it/s]\n",
      "12500it [01:02, 200.55it/s]\n",
      "12500it [00:47, 262.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from lazyme import find_files\n",
    "import io\n",
    "\n",
    "def tokenize_data(path_to_dir, file_ext):\n",
    "    for filename in tqdm(find_files(path_to_dir, file_ext)):\n",
    "        with io.open(filename,encoding='utf8') as fin:\n",
    "            yield word_tokenize(fin.read())\n",
    "        \n",
    "X_train_pos = list(tokenize_data('aclImdb/train/pos/', '*.txt'))\n",
    "X_train_neg = list(tokenize_data('aclImdb/train/neg/', '*.txt'))\n",
    "X_test_pos = list(tokenize_data('aclImdb/test/pos/', '*.txt'))\n",
    "X_test_neg = list(tokenize_data('aclImdb/test/neg/', '*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_pos + X_train_neg\n",
    "X_test = X_test_pos + X_test_neg\n",
    "\n",
    "y_train = ['pos'] * len(X_train_pos) + ['neg'] * len(X_train_neg)\n",
    "y_test = ['pos'] * len(X_test_pos) + ['neg'] * len(X_test_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create our IMDB PyTorch Dataset \n",
    "\n",
    "Although we have a binary class problem, we will demonstrate a multi-class solution issue that can be also used on binary classification. \n",
    "\n",
    "\n",
    "First trick is to convert the \"human\" labels to a one-hot encoding.\n",
    "\n",
    "For example, if we have \n",
    "\n",
    "| Text Index | Label |\n",
    "|:-|:-|\n",
    "|0 | pos|\n",
    "|1 |neg|\n",
    "|2 |pos|\n",
    "|3 |neu|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the \n",
    "\n",
    " - first position of the label vector to represent negative  \n",
    " - second to represent positive\n",
    " - third to represent neutral\n",
    "\n",
    "\n",
    "we should represent the labels as such:\n",
    "\n",
    "| Text Index | Label | One-hot |\n",
    "|:-|:-|:-|\n",
    "|0 | 1|[0, 1, 0]|\n",
    "|1 | 0|[1, 0, 0]|\n",
    "|2 | 1|[0, 1, 0]|\n",
    "|3 | 2|[0, 0, 1]|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the one-hot encoding:\n",
    "labels = [1, 0, 1, 2]\n",
    "torch.eye(max(labels)+1)[labels] #torch.eye gives identity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'one_hot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-263aedd91a7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# In PyTorch version 1.0.1, simply use this:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'one_hot'"
     ]
    }
   ],
   "source": [
    "# In PyTorch version 1.0.1, simply use this:\n",
    "labels = [1, 0, 1, 2]\n",
    "torch.one_hot([1, 0, 1, 2])\n",
    "\n",
    "#no problem if there is attribute error in this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'smart_open'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c07cec6df1c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \"\"\"\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\parsing\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401\n\u001b[0m\u001b[0;32m      5\u001b[0m                             \u001b[0mstrip_tags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrip_short\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrip_numeric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                             \u001b[0mstrip_non_alphanum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrip_multiple_whitespaces\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\parsing\\preprocessing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msmart_open\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'smart_open'"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in c:\\users\\monis\\anaconda3\\lib\\site-packages (19.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install --upgrade gensim>=3.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.vocab = Dictionary(texts)\n",
    "        # Vectorize labels\n",
    "        label_set = {'neg':0, 'pos':1}\n",
    "        labels = [label_set[l] for l in labels]\n",
    "        self.labels = torch.tensor(labels).long()\n",
    "        # Keep track of how many data points.\n",
    "        self._len = len(texts)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        vectorized_sent = self.vectorize(self.texts[index])\n",
    "        return {'x':vectorized_sent, \n",
    "                'y':self.labels[index], \n",
    "                'x_len':len(vectorized_sent)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def vectorize(self, tokens):\n",
    "        \"\"\"\n",
    "        :param tokens: Tokens that should be vectorized. \n",
    "        :type tokens: list(str)\n",
    "        \"\"\"\n",
    "        # See https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx \n",
    "        # Lets just cast list of indices into torch tensors directly =)\n",
    "        return torch.tensor(self.vocab.doc2idx(tokens))\n",
    "    \n",
    "    def unvectorize(self, indices):\n",
    "        \"\"\"\n",
    "        :param indices: Converts the indices back to tokens.\n",
    "        :type tokens: list(int)\n",
    "        \"\"\"\n",
    "        return [self.vocab[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = IMDBDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([ 4, 17, 33, 43, 27, 34, 38, 44, 42, 21, 17, 31, 35, 32, 37, 30, 24, 45,\n",
      "        26,  2,  6, 17, 33, 46,  7, 10, 28, 19, 25,  0,  8, 13, 28, 17, 39, 41,\n",
      "         2, 14,  9, 23, 28, 20, 18, 40,  2, 15, 24,  3, 16, 14, 12,  1,  5, 29,\n",
      "        22, 17, 36, 11,  2]), 'y': tensor(1), 'x_len': 59}\n"
     ]
    }
   ],
   "source": [
    "print(imdb_data[0]) # First data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch DataLoader\n",
    "\n",
    "The [`torch.utils.data.DataLoader` object](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)  will help us easily create batches from the `torch.utils.data.Dataset` so that we can do mini-batch SGD and fully utilize GPU/CPU computation during gradient optimization.\n",
    "\n",
    "The `DataLoader` requires the following function to be implemented in the `Dataset`:\n",
    "\n",
    " - `__getitem__`: Return the dictionary of inputs \n",
    " - `__len__`: Return the no. of indices that `__getitem__` can fetch\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "dataloader = DataLoader(dataset=imdb_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[ 1072,    53, 20332,    53,  2573,     2,  5698, 12440,  3131,    43,\n",
      "           722,   149,    33,    35,   149,  2299,     2,   608,    28,  7202,\n",
      "            17,  2778,    46,   149,    33,   409,   372,   332,   270,   535,\n",
      "           267,   149, 25242,    35,   149,  2299,     2,    14,   949,   183,\n",
      "            35,   149,    33,   194,   149,  2689,    53,   990,     2,    14,\n",
      "          4449,   183,   194,   149,  1072,   366, 13299,    35,   149,   477,\n",
      "           447,  5192,   162,  4215,  3505, 32134,     2,    14,  4352,    28,\n",
      "          2867,    84, 83691,     2,  1815,    53,  6976,    45,    53,   149,\n",
      "           477,  1115,   155,  1236,   267,  2223,  2367,   152,   269,    17,\n",
      "          1245,  1560,   162,    17,  2906,  1284,     2,   237,   194,  3213,\n",
      "            43,   523,  2136,   341, 55701,    44,   194,  3098,    17,  1268,\n",
      "            35, 80433, 22509,  6791,   257,   149,  2136,   455,  1216,   341,\n",
      "           149,  5128,   139, 14451, 55701,   341,   149, 43205,  3476,     2,\n",
      "           234,   454,   332,   266,   407,    35,  3609,    53,  1582,   152,\n",
      "          8187,    45,    33,     2]]), 'y': tensor([[1., 0.]]), 'x_len': tensor([144])}\n"
     ]
    }
   ],
   "source": [
    "for data_dict in dataloader:\n",
    "    # Sort indices of data in batch by lengths.\n",
    "    sorted_indices = np.array(data_dict['x_len']).argsort()[::-1].tolist() #sorts in reverse\n",
    "    data_batch = {name:_tensor[sorted_indices]\n",
    "                  for name, _tensor in data_dict.items()}\n",
    "    print(data_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets try batch of size > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "dataloader = DataLoader(dataset=imdb_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data_dict in dataloader:\n",
    "    # Sort indices of data in batch by lengths.\n",
    "    sorted_indices = np.array(data_dict['x_len']).argsort()[::-1].tolist()\n",
    "    data_batch = {name:_tensor[sorted_indices]\n",
    "                  for name, _tensor in data_dict.items()}\n",
    "    print(data_batch)\n",
    "    break\n",
    "    \n",
    "#You will get an error here because they are not fixed size tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gotcha! Everything should be a fixed-size tensor\n",
    "\n",
    "To use the `DataLoader` to generate batches, one thing that we need to keep consistent is the size of the tensors for our inputs and outputs. \n",
    "\n",
    "For the outputs (`y`), it shouldn't be much of a problem since they are already in fixed size one-hot encoding.\n",
    "\n",
    "It's the inputs (`x`), that has variable length and we need to somehow fix it. \n",
    "\n",
    "There are a couple of ways to accomplish the fixed-size inputs:\n",
    "\n",
    " - Set the size of `x` tensors to a certain size and cut-off extra words after that\n",
    " - Set the size of `x` tensors to the max length seen in the train data and pad the other data points with lower length with a special `<pad>` symbol. \n",
    " \n",
    " \n",
    "Lets do both:\n",
    "\n",
    " - Set a max size limit\n",
    " - For sentences that has length > max, we cut the rest of the sentence off\n",
    " - For sentences that has length < max, we pad till we reach the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "tensor([-1.2528,  0.1755, -0.4251,  0.9689,  1.3231, -0.1331,  0.5136,  2.1149,\n",
      "         1.2246, -0.7345])\n"
     ]
    }
   ],
   "source": [
    "# Here's a clean way to pad 1-Dimensional tensors in PyTorch\n",
    "a = torch.randn(10)\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n",
      "tensor([-1.2528,  0.1755, -0.4251,  0.9689,  1.3231, -0.1331,  0.5136,  2.1149,\n",
      "         1.2246, -0.7345,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "max_len = 15\n",
    "pad_left = 0\n",
    "pad_right = max_len - len(a)\n",
    "b = F.pad(a, (pad_left, pad_right), 'constant') #for text we only pad left and right\n",
    "print(b.shape)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to rewrite the `IMDBDataset` to account for fixed-length `x` tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        \n",
    "        # Remember the `patch_with_special_tokens` from gensim?\n",
    "        # Now we can put it into good use.\n",
    "        special_tokens = {'<pad>': 0, '<unk>':1}\n",
    "        self.vocab = Dictionary(texts)\n",
    "        self.vocab.patch_with_special_tokens(special_tokens)\n",
    "        # Keep track of vocab size.\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        \n",
    "        # Vectorize labels\n",
    "        label_set = {'neg':0, 'pos':1}\n",
    "        labels = [label_set[l] for l in labels]\n",
    "        # Keep track of num of labels.\n",
    "        self.num_labels = max(labels)+1\n",
    "        self.labels = torch.tensor(labels).long()\n",
    "        self.labels_onehot = torch.eye(self.num_labels)[labels].long()\n",
    "        \n",
    "        # Keep track of how many data points.\n",
    "        self._len = len(texts)\n",
    "        \n",
    "        # Find the longest text in the data.\n",
    "        self.max_len = max(len(txt) for txt in texts)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        vectorized_sent = self.vectorize(self.texts(index))\n",
    "        # To pad the sentence:\n",
    "        # Pad left = 0; Pad right = max_len - len of sent.\n",
    "        pad_dim = (0, self.max_len - len(vectorized_sent))\n",
    "        vectorized_sent = F.pad(vectorized_sent, pad_dim, 'constant')\n",
    "        return {'x':vectorized_sent, \n",
    "                'y':self.labels[index], \n",
    "                'x_len':len(vectorized_sent)}\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def vectorize(self, tokens):\n",
    "        \"\"\"\n",
    "        :param tokens: Tokens that should be vectorized. \n",
    "        :type tokens: list(str)\n",
    "        \"\"\"\n",
    "        # See https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx \n",
    "        # Lets just cast list of indices into torch tensors directly =)\n",
    "        return torch.tensor(self.vocab.doc2idx(tokens, unknown_word_index=1))\n",
    "    \n",
    "    def unvectorize(self, indices):\n",
    "        \"\"\"\n",
    "        :param indices: Converts the indices back to tokens.\n",
    "        :type tokens: list(int)\n",
    "        \"\"\"\n",
    "        return [self.vocab[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = IMDBDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.vocab.token2id['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([ 4, 17, 33,  ...,  0,  0,  0]), 'y': tensor(1), 'x_len': 2818}"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[  165,  1771,   625,  ...,     0,     0,     0],\n",
      "        [  163,   156,  1202,  ...,     0,     0,     0],\n",
      "        [   14,   174,    28,  ...,     0,     0,     0],\n",
      "        [  667, 30633,    84,  ...,     0,     0,     0],\n",
      "        [  608,   777,  1197,  ...,     0,     0,     0]]), 'y': tensor([1, 1, 0, 1, 0]), 'x_len': tensor([2818, 2818, 2818, 2818, 2818])}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "dataloader = DataLoader(dataset=imdb_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data_dict in dataloader:\n",
    "    # Sort indices of data in batch by lengths.\n",
    "    sorted_indices = np.array(data_dict['x_len']).argsort()[::-1].tolist()\n",
    "    data_batch = {name:_tensor[sorted_indices]\n",
    "                  for name, _tensor in data_dict.items()}\n",
    "    print(data_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model with Feed-Forward Net\n",
    "\n",
    "Now that we have everything about the data in place, we can make use of all the knowledge we've gained thus far:\n",
    "\n",
    " - **Multi-Layered Perceptron**, aka. **Feed-Forward Network** that we've learnt from the previous XOR examples\n",
    "   - *Linear* layers\n",
    "   - *Activation function*, which?\n",
    "   - *Criterion* which?\n",
    "   - *Optimizer*, Adam vs SGD\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 2\n",
    "max_len = 2818\n",
    "class FFNet(nn.Module):\n",
    "    def __init__(self, max_len, num_labels, vocab_size, embedding_size, hidden_dim):\n",
    "        super(FFNet, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size,\n",
    "                                       embedding_dim=embedding_size, \n",
    "                                       padding_idx=0)\n",
    "        # The no. of inputs to the linear layer is the \n",
    "        # no. of tokens in each input * embedding_size\n",
    "        self.linear1 = nn.Linear(2818 * embedding_size, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # We want to flatten the inputs so that we get the matrix of shape.\n",
    "        # batch_size x no. of tokens in each input * embedding_size\n",
    "        batch_size, max_len = inputs.shape\n",
    "        embedded = self.embeddings(inputs).view(batch_size, -1) # Change the size of the embedded matrix.\n",
    "        hid = F.relu(self.linear1(embedded))\n",
    "        out = self.linear2(hid)\n",
    "        return F.sigmoid(out) #sigmoid is used for binary classification\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Training Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6863493323326111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "embedding_size = 100\n",
    "learning_rate = 0.003\n",
    "hidden_size = 100\n",
    "\n",
    "# Initialize the dataset.\n",
    "batch_size = 5\n",
    "imdb_data = IMDBDataset(X_train,y_train)\n",
    "dataloader = DataLoader(dataset=imdb_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # because we use sigmoid in the above block of code, we should use use binary cross entropy loss\n",
    "# Hint: the CBOW model object you've created.\n",
    "model = FFNet(imdb_data.max_len, \n",
    "              imdb_data.num_labels, \n",
    "              imdb_data.vocab_size, \n",
    "              embedding_size=embedding_size, \n",
    "              hidden_dim=hidden_size).to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#model = nn.DataParallel(model)\n",
    "\n",
    "losses = []\n",
    "num_epochs = 5\n",
    "for _e in range(num_epochs):\n",
    "    epoch_loss = []\n",
    "    for batch in tqdm(dataloader):\n",
    "        x = batch['x'].to(device)\n",
    "        y = batch['y'].to(device)\n",
    "        # Zero gradient.\n",
    "        optimizer.zero_grad()\n",
    "        # Feed forward.\n",
    "        predictions = model(x)\n",
    "        loss = criterion(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(float(loss))\n",
    "        #break\n",
    "    print(sum(epoch_loss)/len(epoch_loss))\n",
    "    #break\n",
    "    losses.append(sum(epoch_loss)/len(epoch_loss))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5063, 0.5023, 0.5161, 0.5047, 0.5059], grad_fn=<MaxBackward0>),\n",
       " tensor([1, 0, 0, 1, 1]))"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(predictions, 1)  # Predictions of the last batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Based', 'on', 'an', 'actual', 'story', ',', 'John', 'Boorman', 'shows', 'the', 'struggle', 'of', 'an', 'American', 'doctor', ',', 'whose', 'husband', 'and', 'son', 'were', 'murdered', 'and', 'she', 'was', 'continually', 'plagued', 'with', 'her', 'loss', '.', 'A', 'holiday', 'to', 'Burma', 'with', 'her', 'sister', 'seemed', 'like', 'a', 'good', 'idea', 'to', 'get', 'away', 'from', 'it', 'all', ',', 'but', 'when', 'her', 'passport', 'was', 'stolen', 'in', 'Rangoon', ',', 'she', 'could', 'not', 'leave', 'the', 'country', 'with', 'her', 'sister', ',', 'and', 'was', 'forced', 'to', 'stay', 'back', 'until', 'she', 'could', 'get', 'I.D', '.', 'papers', 'from', 'the', 'American', 'embassy', '.', 'To', 'fill', 'in', 'a', 'day', 'before', 'she', 'could', 'fly', 'out', ',', 'she', 'took', 'a', 'trip', 'into', 'the', 'countryside', 'with', 'a', 'tour', 'guide', '.', '``', 'I', 'tried', 'finding', 'something', 'in', 'those', 'stone', 'statues', ',', 'but', 'nothing', 'stirred', 'in', 'me', '.', 'I', 'was', 'stone', 'myself', '.', \"''\", '<', 'br', '/', '>', '<', 'br', '/', '>', 'Suddenly', 'all', 'hell', 'broke', 'loose', 'and', 'she', 'was', 'caught', 'in', 'a', 'political', 'revolt', '.', 'Just', 'when', 'it', 'looked', 'like', 'she', 'had', 'escaped', 'and', 'safely', 'boarded', 'a', 'train', ',', 'she', 'saw', 'her', 'tour', 'guide', 'get', 'beaten', 'and', 'shot', '.', 'In', 'a', 'split', 'second', 'she', 'decided', 'to', 'jump', 'from', 'the', 'moving', 'train', 'and', 'try', 'to', 'rescue', 'him', ',', 'with', 'no', 'thought', 'of', 'herself', '.', 'Continually', 'her', 'life', 'was', 'in', 'danger', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'Here', 'is', 'a', 'woman', 'who', 'demonstrated', 'spontaneous', ',', 'selfless', 'charity', ',', 'risking', 'her', 'life', 'to', 'save', 'another', '.', 'Patricia', 'Arquette', 'is', 'beautiful', ',', 'and', 'not', 'just', 'to', 'look', 'at', ';', 'she', 'has', 'a', 'beautiful', 'heart', '.', 'This', 'is', 'an', 'unforgettable', 'story', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', \"''\", 'We', 'are', 'taught', 'that', 'suffering', 'is', 'the', 'one', 'promise', 'that', 'life', 'always', 'keeps', '.', \"''\"]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0]) # First test review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-ab8beda5162c>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-ab8beda5162c>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    pad_dim = ???\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "max_len = 2818\n",
    "def vectorize_test_inputs(inputs):\n",
    "    # Process the input text in the same way as you did with the training data.\n",
    "    vectorized_sent = imdb_data.vectorize(inputs)\n",
    "    pad_dim = (0, max_len - len(vectorized_sent))\n",
    "    vectorized_sent = F.pad(vectorized_sent, pad_dim, 'constant')\n",
    "    return vectorized_sent.unsqueeze(0)\n",
    "\n",
    "print('Input tensor:', vectorize_test_inputs(X_test[0]))\n",
    "label_set = {'neg':0, 'pos':1}\n",
    "print('Label:', label_set[y_test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5093, 0.5479])\n",
      "tensor([0.4903, 0.5097])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Apply the model to the inputs.\n",
    "with torch.no_grad():\n",
    "    predictions = model(vectorize_test_inputs(X_test[0])).unsqueeze(0)\n",
    "    print(predictions)\n",
    "    print(F.softmax(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
